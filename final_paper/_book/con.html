<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 6 Conclusion | Machine Learning for Biological Sciences</title>
  <meta name="description" content="Final paper for CAMB 698 covering machine learning topics">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 6 Conclusion | Machine Learning for Biological Sciences />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Final paper for CAMB 698 covering machine learning topics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Conclusion | Machine Learning for Biological Sciences />
  
  <meta name="twitter:description" content="Final paper for CAMB 698 covering machine learning topics" />
  

<meta name="author" content="Vincent Wu">


<meta name="date" content="2018-12-10">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="unsup-learn.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">CAMB 698 Final Paper</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Foreword</a></li>
<li class="chapter" data-level="2" data-path="bg.html"><a href="bg.html"><i class="fa fa-check"></i><b>2</b> Background</a></li>
<li class="chapter" data-level="3" data-path="dim-red.html"><a href="dim-red.html"><i class="fa fa-check"></i><b>3</b> Dimensionality reduction</a><ul>
<li class="chapter" data-level="3.1" data-path="dim-red.html"><a href="dim-red.html#introduction-to-dimensionality-reduction"><i class="fa fa-check"></i><b>3.1</b> Introduction to dimensionality reduction</a></li>
<li class="chapter" data-level="3.2" data-path="dim-red.html"><a href="dim-red.html#pca-and-pcoa"><i class="fa fa-check"></i><b>3.2</b> PCA and PCoA</a><ul>
<li class="chapter" data-level="3.2.1" data-path="dim-red.html"><a href="dim-red.html#pcoa-example"><i class="fa fa-check"></i><b>3.2.1</b> PCoA example</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="dim-red.html"><a href="dim-red.html#t-sne"><i class="fa fa-check"></i><b>3.3</b> t-SNE</a><ul>
<li class="chapter" data-level="3.3.1" data-path="dim-red.html"><a href="dim-red.html#t-sne-example"><i class="fa fa-check"></i><b>3.3.1</b> t-SNE example</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="dim-red.html"><a href="dim-red.html#other-dimensionality-reduction-techniques"><i class="fa fa-check"></i><b>3.4</b> Other dimensionality reduction techniques</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sup-learn.html"><a href="sup-learn.html"><i class="fa fa-check"></i><b>4</b> Supervised Learning</a><ul>
<li class="chapter" data-level="4.1" data-path="sup-learn.html"><a href="sup-learn.html#introduction-to-supervised-learning"><i class="fa fa-check"></i><b>4.1</b> Introduction to supervised learning</a></li>
<li class="chapter" data-level="4.2" data-path="sup-learn.html"><a href="sup-learn.html#regressions"><i class="fa fa-check"></i><b>4.2</b> Regressions</a><ul>
<li class="chapter" data-level="4.2.1" data-path="sup-learn.html"><a href="sup-learn.html#linear-regression-example"><i class="fa fa-check"></i><b>4.2.1</b> Linear regression example</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="sup-learn.html"><a href="sup-learn.html#k-nearest-neighbors-knn"><i class="fa fa-check"></i><b>4.3</b> K-nearest neighbors (KNN)</a><ul>
<li class="chapter" data-level="4.3.1" data-path="sup-learn.html"><a href="sup-learn.html#knn-example"><i class="fa fa-check"></i><b>4.3.1</b> KNN example</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="sup-learn.html"><a href="sup-learn.html#decision-trees"><i class="fa fa-check"></i><b>4.4</b> Decision trees</a></li>
<li class="chapter" data-level="4.5" data-path="sup-learn.html"><a href="sup-learn.html#random-forests"><i class="fa fa-check"></i><b>4.5</b> Random forests</a></li>
<li class="chapter" data-level="4.6" data-path="sup-learn.html"><a href="sup-learn.html#neural-networks-nn"><i class="fa fa-check"></i><b>4.6</b> Neural networks (NN)</a></li>
<li class="chapter" data-level="4.7" data-path="sup-learn.html"><a href="sup-learn.html#support-vector-machines-svm"><i class="fa fa-check"></i><b>4.7</b> Support vector machines (SVM)</a><ul>
<li class="chapter" data-level="4.7.1" data-path="sup-learn.html"><a href="sup-learn.html#svm-example"><i class="fa fa-check"></i><b>4.7.1</b> SVM example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="unsup-learn.html"><a href="unsup-learn.html"><i class="fa fa-check"></i><b>5</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="5.1" data-path="unsup-learn.html"><a href="unsup-learn.html#introduction-to-unsupervised-learning"><i class="fa fa-check"></i><b>5.1</b> Introduction to unsupervised learning</a></li>
<li class="chapter" data-level="5.2" data-path="unsup-learn.html"><a href="unsup-learn.html#hierarchical-agglomerative-clustering"><i class="fa fa-check"></i><b>5.2</b> Hierarchical agglomerative clustering</a></li>
<li class="chapter" data-level="5.3" data-path="unsup-learn.html"><a href="unsup-learn.html#hierarchical-divisive-clustering"><i class="fa fa-check"></i><b>5.3</b> Hierarchical divisive clustering</a><ul>
<li class="chapter" data-level="5.3.1" data-path="unsup-learn.html"><a href="unsup-learn.html#k-means-example"><i class="fa fa-check"></i><b>5.3.1</b> K-means example</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="unsup-learn.html"><a href="unsup-learn.html#hidden-markov-models-hmm"><i class="fa fa-check"></i><b>5.4</b> Hidden Markov models (HMM)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="con.html"><a href="con.html"><i class="fa fa-check"></i><b>6</b> Conclusion</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning for Biological Sciences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="con" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Conclusion</h1>
<p>The techniques mentioned in this paper are only a subset of the wide spectrum of techniques that are being used and developed. These methods, spanning from linear regression to hidden Markov models, are all context dependent – in terms of the data (i.e. whether there is missing data, categorical vs continuous, etc.) and the hypotheses that one is trying to answer. Choosing the “right” method is not an easy task and must also take into account what has been done in the field. Furthermore, the increased communication and synergy between research fields has allowed for novel applications of a field’s existing tools/methods to a different field.</p>
<p>During a discussion one day, my class mentor and I referred to a saying that “all models are wrong; but some are less wrong than others”<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>. While it may seem unfortunate, this quote has some validity. For instance, the human eye and brain can distinguish clusters and grouping that are difficult for computers to recapitulate. In the PCoA plot that was used in this paper, we are capable of quickly discerning the groups manually by eye. However, using our own eyes leaves room for error and potential inconsistencies across people. As such, my view of machine learning is as a way of emulating and improving on what humans can do – lending itself to the idea of “learning”.</p>
<p>The benefits of machine learning methods far outweigh the limitations. Machine learning can process data on a larger and faster scale than we can, especially in higher dimensional spaces with many data points. These methods are capable of processing and understanding the underlying relationships within data – especially from sources like next-generation sequencing. Developing new techniques as well as improving the accessibility of existing techniques to the larger scientific community will create opportunities for unique questions to be answered.</p>

<div id="refs" class="references">
<div>
<p>Acharya, U Rajendra, Shu Lih Oh, Yuki Hagiwara, Jen Hong Tan, and Hojjat Adeli. 2018. “Deep Convolutional Neural Network for the Automated Detection and Diagnosis of Seizure Using Eeg Signals.” <em>Computers in Biology and Medicine</em> 100. Elsevier: 270–78.</p>
</div>
<div>
<p>Becht, Etienne, Leland McInnes, John Healy, Charles-Antoine Dutertre, Immanuel WH Kwok, Lai Guan Ng, Florent Ginhoux, and Evan W Newell. 2018. “Dimensionality Reduction for Visualizing Single-Cell Data Using Umap.” <em>Nature Biotechnology</em>. Nature Publishing Group.</p>
</div>
<div>
<p>Boehmke, Bradley. 2018. “UC Business Analytics R Programming Guide.” <a href="https://uc-r.github.io/hc_clustering#algorithms" class="uri">https://uc-r.github.io/hc_clustering#algorithms</a>.</p>
</div>
<div>
<p>Box, George EP. 1976. “Science and Statistics.” <em>Journal of the American Statistical Association</em> 71 (356). Taylor &amp; Francis: 791–99.</p>
</div>
<div>
<p>———. 1979. “Robustness in the Strategy of Scientific Model Building.” In <em>Robustness in Statistics</em>, 201–36. Elsevier.</p>
</div>
<div>
<p>Breiman, Leo. 2001. “Random Forests.” <em>Machine Learning</em> 45 (1). Springer: 5–32.</p>
</div>
<div>
<p>Buggert, Marcus, Son Nguyen, Gonzalo Salgado-Montes de Oca, Bertram Bengsch, Samuel Darko, Amy Ransier, Emily R Roberts, et al. 2018. “Identification and Characterization of Hiv-Specific Resident Memory Cd8+ T Cells in Human Lymphoid Tissue.” <em>Science Immunology</em> 3 (24). Science Immunology: eaar4526.</p>
</div>
<div>
<p>Byrd, Allyson L, Clay Deming, Sara KB Cassidy, Oliver J Harrison, Weng-Ian Ng, Sean Conlan, Yasmine Belkaid, et al. 2017. “Staphylococcus Aureus and Staphylococcus Epidermidis Strain Diversity Underlying Pediatric Atopic Dermatitis.” <em>Science Translational Medicine</em> 9 (397). American Association for the Advancement of Science: eaal4651.</p>
</div>
<div>
<p>Eddy, Sean R. 2004. “What Is a Hidden Markov Model?” <em>Nature Biotechnology</em> 22 (10). Nature Publishing Group: 1315.</p>
</div>
<div>
<p>Eddy, Sean R. 1998. “Profile Hidden Markov Models.” <em>Bioinformatics (Oxford, England)</em> 14 (9): 755–63.</p>
</div>
<div>
<p>Ercal, Fikret, Anurag Chawla, William V Stoecker, Hsi-Chieh Lee, and Randy H Moss. 1994. “Neural Network Diagnosis of Malignant Melanoma from Color Images.” <em>IEEE Transactions on Biomedical Engineering</em> 41 (9). IEEE: 837–45.</p>
</div>
<div>
<p>Esteva, Andre, Brett Kuprel, Roberto A Novoa, Justin Ko, Susan M Swetter, Helen M Blau, and Sebastian Thrun. 2017. “Dermatologist-Level Classification of Skin Cancer with Deep Neural Networks.” <em>Nature</em> 542 (7639). Nature Publishing Group: 115.</p>
</div>
<div>
<p>Finn, Robert D, Jody Clements, and Sean R Eddy. 2011. “HMMER Web Server: Interactive Sequence Similarity Searching.” <em>Nucleic Acids Research</em> 39 (suppl_2). Oxford University Press: W29–W37.</p>
</div>
<div>
<p>Furey, Terrence S, Nello Cristianini, Nigel Duffy, David W Bednarski, Michel Schummer, and David Haussler. 2000. “Support Vector Machine Classification and Validation of Cancer Tissue Samples Using Microarray Expression Data.” <em>Bioinformatics</em> 16 (10). Oxford University Press: 906–14.</p>
</div>
<div>
<p>Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. MIT Press.</p>
</div>
<div>
<p>Guyon, Isabelle, Jason Weston, Stephen Barnhill, and Vladimir Vapnik. 2002. “Gene Selection for Cancer Classification Using Support Vector Machines.” <em>Machine Learning</em> 46 (1-3). Springer: 389–422.</p>
</div>
<div>
<p>Harrison, Onel. 2018. “Machine Learning Basics with the K-Nearest Neighbors Algorithm.” <a href="https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761" class="uri">https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761</a>.</p>
</div>
<div>
<p>Kappen, HJ, and JP Neijt. 1993. “Neural Network Analysis to Predict Treatment Outcome.” <em>Annals of Oncology</em> 4 (suppl_4). Oxford University Press: S31–S34.</p>
</div>
<div>
<p>Le, James. 2018. “Support Vector Machines in R.” <a href="https://www.datacamp.com/community/tutorials/support-vector-machines-r" class="uri">https://www.datacamp.com/community/tutorials/support-vector-machines-r</a>.</p>
</div>
<div>
<p>Liaw, Andy, Matthew Wiener, and others. 2002. “Classification and Regression by randomForest.” <em>R News</em> 2 (3): 18–22.</p>
</div>
<div>
<p>Maaten, Laurens van der, and Geoffrey Hinton. 2008. “Visualizing Data Using T-Sne.” <em>Journal of Machine Learning Research</em> 9 (Nov): 2579–2605.</p>
</div>
<div>
<p>Manning, Christopher D., Prabhakar Raghavan, and Hinrich Schütze. 2008. <em>Introduction to Information Retrieval</em>. Cambridge University Press. <a href="https://www.amazon.com/Introduction-Information-Retrieval-Christopher-Manning/dp/0521865719?SubscriptionId=AKIAIOBINVZYXZQZ2U3A&amp;tag=chimbori05-20&amp;linkCode=xm2&amp;camp=2025&amp;creative=165953&amp;creativeASIN=0521865719" class="uri">https://www.amazon.com/Introduction-Information-Retrieval-Christopher-Manning/dp/0521865719?SubscriptionId=AKIAIOBINVZYXZQZ2U3A&amp;tag=chimbori05-20&amp;linkCode=xm2&amp;camp=2025&amp;creative=165953&amp;creativeASIN=0521865719</a>.</p>
</div>
<div>
<p>Nielsen, Michael A. 2015. <em>Neural Networks and Deep Learning</em>. Determination Press.</p>
</div>
<div>
<p>Rabiner, Lawrence R, and Biing-Hwang Juang. 1986. “An Introduction to Hidden Markov Models.” <em>Ieee Assp Magazine</em> 3 (1). Citeseer: 4–16.</p>
</div>
<div>
<p>Sehra, Chirag. 2018. “Decision Trees Explained Easily.” Medium. <a href="https://medium.com/@chiragsehra42/decision-trees-explained-easily-28f23241248" class="uri">https://medium.com/@chiragsehra42/decision-trees-explained-easily-28f23241248</a>.</p>
</div>
<div>
<p>Shalizi, Cosma Rohilla. 2018. <em>Advanced Data Analysis from an Elementary Point of View</em>. Pittsburgh, PA: Carnegie Mellon University. <a href="http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/" class="uri">http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/</a>.</p>
</div>
<div>
<p>Snow, Peter B, Deborah S Smith, and William J Catalona. 1994. “Artificial Neural Networks in the Diagnosis and Prognosis of Prostate Cancer: A Pilot Study.” <em>The Journal of Urology</em> 152 (5). Elsevier: 1923–6.</p>
</div>
<div>
<p>Strayer, Nick. 2018. “T-Sne Explained in Plain Javascript.” <a href="https://beta.observablehq.com/@nstrayer/t-sne-explained-in-plain-javascript" class="uri">https://beta.observablehq.com/@nstrayer/t-sne-explained-in-plain-javascript</a>.</p>
</div>
<div>
<p>Zheng, Qi, Casey Bartow-McKenney, Jacquelyn S Meisel, and Elizabeth A Grice. 2018. “HmmUFOtu: An Hmm and Phylogenetic Placement Based Ultra-Fast Taxonomic Assignment and Otu Picking Tool for Microbiome Amplicon Sequencing Studies.” <em>Genome Biology</em> 19 (1). BioMed Central: 82.</p>
</div>
</div>
</div>









<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>This is a modified version of George E.P. Box’s quote from two of his papers: “All models are wrong but some are useful” <span class="citation">(Box <a href="#ref-box1976science">1976</a>; Box <a href="#ref-box1979robustness">1979</a>)</span>.<a href="con.html#fnref4">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="unsup-learn.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["final_paper.pdf", "final_paper.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
